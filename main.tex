\documentclass[a4paper, 	% Seitenformat
		12pt, 								% Schriftgr��e
		bibliography=totoc, 	% Literaturverzeichnis in das Inhaltsverzeichnis
		index=totoc, 	% Index in das Inhaltsverzeichnis
		abstract=true, 	% mit Abstrakt
		headsepline, 	% Trennlinie f�r die Kopfzeile
		%footnosepline,	% Trennlinie f�r die Fusszeile
		]{scrartcl}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage[english]{babel}
%\usepackage{ulem}
% Bilder
%\usepackage{pst-all}		% Zeichnungen in Latex (kein pdflatex)
\usepackage{subfig}	  		% Unterteilungen von Abbildungen
\usepackage{float}		  	% Gleitobjekte
\usepackage{graphicx}		% Einbinden von Graphiken aus Dateien
\usepackage{rotating}   	% Die folgenden Packages sind meist hilfreich f�r das Erstellen von Arbeiten
\usepackage{mathrsfs}
\usepackage{eurosym,bm,amsmath,amssymb,verbatim}
\usepackage{listings}
\usepackage[T1]{fontenc}
\usepackage{setspace}
\usepackage [round,authoryear] {natbib} % Notwendiges Package f�r den verwendeten Literaturstil
%\usepackage{natbib}
\usepackage{xcolor}
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny,textwidth=2cm]{todonotes}
%------------------------------------------------------------------------

\parindent0em 					% kein Einzug nach einer Leerzeile
\setlength{\parskip}{1em}			
\topmargin-20.4mm   			% F�r die R�nder
\textheight245mm
\textwidth157mm \oddsidemargin11mm \evensidemargin11mm
\hyphenpenalty=100
\exhyphenpenalty=100

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}					% Start des Dokuments
\begin{titlepage}

\hspace{12cm}\scalebox{0.3}{\includegraphics{Unilogo.jpg}}

\vspace*{1cm}
\large\textbf{Disposition: }\\[0.5cm]
\large\textbf{From Statistics to Machine Learning: \\ A Comparative Study of Outlier Detection Methods \\ in Multidimensional Data}\\[0.5cm]

Studiengang: Betriebswirtschaftslehre\\

Lehrstuhl für Statistik\\[1.5cm]
%
%
\noindent\begin{tabular}[h]{@{}ll}
%\begin{tabular}{l l}
Eingereicht bei: &Prof. Dr. Yarema Okhrin \\
\\
Betreuer: &Herr Philipp Haid 			 \\
\\
Vorgelegt von:   &Thore Johannsen         \\
\\
Adresse: &Salomon-Idler-Straße 4         \\[0.2cm]
                 &Augsburg                      \\
\\
Matrikel-Nr.:    &2231165                 \\
\\
Email:           &thore.johannsen@outlook.com     \\
\\
\end{tabular}
\vfill
Augsburg, im September 2010
\end{titlepage}
\newpage
\pagenumbering{Roman}


\tableofcontents		    % Inhaltsverzeichnis
\newpage
%\listoffigures			    % Abbildungsverzeichnis
%\listoftables				  % Tabellenverzeichnis

\clearpage
\pagenumbering{arabic}
\onehalfspacing 			     % F�r richtigen Zeilenabstand

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\input{Chapter/Disposition}  % Zur besseren Strukturierung empfiehlt es sich das Dokument aufzuteilen.
\newpage
\input{Chapter/Einführung}
\newpage
\input{Chapter/Methods}
\newpage
\input{Chapter/Benchmarking}
\newpage
\input{Chapter/Results}
%\vspace{5em}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Survey about 

The fundamental idea of statistical-based techniques in labeling or identifying outliers depends on the relationship with
the distribution model. These methods are usually classified into two main groups - the parametric and non-parametric
methods. 
The key idea for clustering-based techniques is the application of standard clustering techniques to detect outliers from
given data. Outliers are considered as the observations that are not within or nearby any large or dense clusters.
Learning-based methods such as active learning and deep learning, the underlying idea is to learn different models
through the application of these learning methods to detect outliers (W19 S.107967 ff)


\newpage 


Concept of my Thesis:
My narrative compares a traditional distance-based method (k-NN) with a modern approach Contrasive Learning approach (Intercont). 
MCD fits as the Classical Statistical Benchmark against which both techniques are measured.
Chapter I: The Need for Robustness (MCD as the Theoretical Gold Standard)
I want to introduce MCD as the foundational method developed in the statistical community to solve the problem of multivariate robust estimation.
It represents the gold standard for defining a "true" outlier based on a well-defined theoretical model (multivariate normality).
The key Concept to Highlight is its high breakdown point %\approx 50\%. 
It can resist contamination that would utterly destroy traditional estimators like the sample mean and covariance. (how much contamination can the others hold up to?)
MCD defines what a robust outlier detection method should achieve in terms of resistance to contamination. 
This sets the bar for robustness.


Chapter II: The Limitations (The Gap that my methods fill)
I want to use MCD's weaknesses to establish the necessity of the methods you are actually comparing (k-NN and Modern ML).
I want to shift the debate to the other methods.
Limitations to Discuss:
Computational Bottleneck: MCD struggles with large N and high P.
I want to state clearly that MCD's strength is simultaneously its greatest weakness: it is a parametric method.
It relies on the strong, central assumption that the clean data follows an elliptical distribution (most often multivariate normal). 
This establishes the need for computationally scalable methods.
Model Dependence: MCD is inherently tied to the assumption of a globally elliptical (e.g., multivariate normal) distribution. 
Use MCD's strict assumptions to motivate the need for non-parametric methods.
MCD's Constraint: Real-world datasets (especially in business, IT, or complex sensors) are rarely normally distributed. 
They are often multi-modal or have complex, non-linear structures. MCD is designed to find global outliers relative to a single, central ellipse.
The Thesis Problem: Because real-world data structures are complex, a method designed to find a single, central data "cloud" (MCD) will fail to identify local outliers or outliers
in non-elliptical shapes. 
This failure is what necessitates the shift to your two core methods.
This assumption often fails in complex, real-world data, leading to the need for non-parametric (k-NN) or distribution-agnostic (Modern ML) methods.
Therefor I will analyze real-world data about financial fraud that was used befor in papers.
Thesis Fit: MCD is too slow and too model-dependent for the types of large, complex datasets you are using.
This explains why k-NN and Modern ML are relevant contenders for modern outlier detection.


Chapter III: Introducing k-NN and InterCont
Defining the two methods and describing their assumptions
Whats special about k-NN and what is special about InterCont?
where are weaknesses?


Chapter IV: Benchmark Comparison (MCD as the Control)
Defining Benchmarks and describing short what "exotic" benchmarks are out there.
Role of MCD: Include MCD in your empirical analysis as a control method or baseline benchmark.
The Comparison Strategy:
Data A (Ideal/Synthetic): Test all three methods on a dataset that is perfectly multivariate normal with scattered outliers. 
Here, MCD should ideally perform the best or, at least, as well as the others in terms of detection rate (Area Under the Curve, AUC). 
This validates the theoretical strength of MCD.
Data B (Real/Complex): Test all three methods on a large, complex, non-elliptical dataset (the type of data where k-NN and Modern ML excel). 
Here, MCD should perform poorly or fail to run efficiently due to its limitations, thereby highlighting the superior scalability and flexibility of k-NN and the Modern ML method.
Thesis Fit: By showing MCD's success on ideal data and its failure on real-world data, you clearly demonstrate the shift in necessary methodology, creating a powerful contrast that
elevates the performance of k-NN and Modern ML. Describe the advantages and disadvantages about the other methods as well


Chapter V: Conclusion
Maybe you can argue are ask a follow up question, if such a comlex method as Intercont is economically reasonable.
You need specially trained employees do set it up and take care of.
Maybe you can try to explain why k-NN is still performing good in comparison to InterCont.
The necessary step from statistics to machine learing is clear and you proven it. 
But is it so clear to implement a deep learing method, when a lazy learner method like k-NN can provide good results as well?


\clearpage
\bibliographystyle{autorjahrdidiDE}  % Dies ist der verwendete Stil f�r Zitation und Literaturverzeichnis																	 % Die Datei autorjahrdidiDE.bst muss in das aktuelle Arbeitsverzeichnis kopiert werden
\bibliography{Literatur}	           % Literaturverzeichnis liegt in der Datei Literatur
\end{document}											 % Ende des Dokuments
